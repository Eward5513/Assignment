{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac2778a",
   "metadata": {},
   "source": [
    "\n",
    "# Financial News Sentiment Classification — End‑to‑End Project\n",
    "\n",
    "**Author:** _Fill your name_  \n",
    "**Last updated:** 2025-11-12 10:16 UTC\n",
    "\n",
    "This notebook performs an end-to-end workflow to classify sentiment (positive / neutral / negative) of financial news headlines/sentences.\n",
    "\n",
    "**What you'll find:**\n",
    "1. **Data Collection**: Load Financial PhraseBank and optionally **scrape recent headlines** (Yahoo Finance / EastMoney).\n",
    "2. **Cleaning & Preprocessing**: lowercase, punctuation removal, stopword removal, lemmatization.\n",
    "3. **Exploratory Data Analysis (EDA)**: class balance, word frequency, word cloud, key terms.\n",
    "4. **Modeling** (3+ models):\n",
    "   - **Multinomial Naive Bayes** (TF‑IDF features)\n",
    "   - **BiLSTM** (pretrained embeddings or randomly initialized)\n",
    "   - **Transformer fine‑tuning** (FinBERT or DistilBERT baseline)\n",
    "5. **Evaluation**: accuracy, precision/recall/F1, confusion matrix; compare models.\n",
    "6. **Application**: apply the best model to **unseen** scraped/manual headlines and interpret predictions.\n",
    "\n",
    "> **Scoring focus**: clarity and depth of data prep, EDA, and model selection rationale. Model performance supports your narrative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f25f51",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Setup\n",
    "Install packages (one-time). If you're in a restricted environment, consider running only classical models (NB+TF‑IDF) first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running locally, uncomment as needed (may take time for Transformers).\n",
    "# %pip install -q numpy pandas scikit-learn matplotlib wordcloud nltk beautifulsoup4 requests lxml\n",
    "# %pip install -q tensorflow==2.* gensim\n",
    "# %pip install -q transformers datasets torch --extra-index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a0e93",
   "metadata": {},
   "source": [
    "## 1. Imports & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, json, math, random, string, time, warnings, itertools, collections\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# NLTK data (first run may download; if blocked, set these manually)\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "try:\n",
    "    nltk.data.find(\"corpora/wordnet\")\n",
    "except LookupError:\n",
    "    nltk.download(\"wordnet\", quiet=True)\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "EN_STOP = set(stopwords.words(\"english\"))\n",
    "LEMM = WordNetLemmatizer()\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "OUT_DIR = Path(\"./outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d154d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data Collection\n",
    "### 2.1 Option A — Load Financial PhraseBank (recommended baseline)\n",
    "Use one of:\n",
    "- **Local CSV**: put `financial_phrasebank.csv` into `./data/`\n",
    "- **HuggingFace**: `datasets.load_dataset(\"financial_phrasebank\", \"sentences_allagree\")`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127af01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_HF = False  # Set to True to try Hugging Face loading\n",
    "\n",
    "df_base = None\n",
    "\n",
    "if USE_HF:\n",
    "    try:\n",
    "        from datasets import load_dataset\n",
    "        ds = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "        df_base = ds[\"train\"].to_pandas().rename(columns={\"sentence\": \"text\", \"label\": \"label_id\"})\n",
    "        id2label = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "        df_base[\"label\"] = df_base[\"label_id\"].map(id2label)\n",
    "    except Exception as e:\n",
    "        print(\"HF loading failed, falling back to local CSV:\", e)\n",
    "\n",
    "if df_base is None:\n",
    "    local_csv = DATA_DIR / \"financial_phrasebank.csv\"\n",
    "    if local_csv.exists():\n",
    "        df_base = pd.read_csv(local_csv)\n",
    "        assert {\"text\",\"label\"}.issubset(df_base.columns)\n",
    "    else:\n",
    "        df_base = pd.DataFrame({\n",
    "            \"text\":[\n",
    "                \"Company X reports record profits in Q3.\",\n",
    "                \"Regulators fine Company Y for accounting violations.\",\n",
    "                \"Market remains unchanged amid mixed economic data.\"\n",
    "            ],\n",
    "            \"label\":[\"positive\",\"negative\",\"neutral\"]\n",
    "        })\n",
    "        print(\"WARNING: No dataset found. Using a tiny placeholder. Please add your dataset to ./data.\")\n",
    "\n",
    "df_base = df_base.dropna(subset=[\"text\",\"label\"]).reset_index(drop=True)\n",
    "df_base.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d653efff",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Option B — Build Your Own Dataset (Scrape recent headlines)\n",
    "Best‑effort scrapers for Yahoo Finance ticker pages and a minimal EastMoney keyword demo. These may break if sites change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_yahoo_ticker_news(ticker=\"AAPL\", max_items=50):\n",
    "    url = f\"https://finance.yahoo.com/quote/{ticker}/news\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, headers=headers, timeout=15)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    items = []\n",
    "    for a in soup.select('a[href*=\"/news/\"]'):\n",
    "        title = a.get_text(strip=True)\n",
    "        href = a.get(\"href\", \"\")\n",
    "        if title and len(title.split()) > 2 and \"/news/\" in href:\n",
    "            if not href.startswith(\"http\"):\n",
    "                href = \"https://finance.yahoo.com\" + href\n",
    "            items.append({\"source\":\"yahoo\", \"ticker\":ticker, \"title\":title, \"url\":href})\n",
    "        if len(items) >= max_items:\n",
    "            break\n",
    "    return pd.DataFrame(items).drop_duplicates(subset=[\"title\"])\n",
    "\n",
    "def scrape_eastmoney_keywords(keyword=\"新能源\", max_pages=1):\n",
    "    rows = []\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    for p in range(1, max_pages+1):\n",
    "        url = f\"https://so.eastmoney.com/news/s?keyword={keyword}&pageindex={p}\"\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            soup = BeautifulSoup(r.text, \"lxml\")\n",
    "            for a in soup.select(\"a\"):\n",
    "                title = a.get_text(strip=True)\n",
    "                href = a.get(\"href\",\"\")\n",
    "                if title and href and (\"eastmoney\" in href or \"finance\" in href):\n",
    "                    rows.append({\"source\":\"eastmoney\",\"keyword\":keyword,\"title\":title,\"url\":href})\n",
    "        except Exception as e:\n",
    "            print(\"EastMoney scrape error:\", e)\n",
    "    df = pd.DataFrame(rows).drop_duplicates(subset=[\"title\"])\n",
    "    return df\n",
    "\n",
    "DF_SCRAPE = pd.DataFrame()\n",
    "try:\n",
    "    df_y_aapl = scrape_yahoo_ticker_news(\"AAPL\", max_items=30)\n",
    "    DF_SCRAPE = pd.concat([DF_SCRAPE, df_y_aapl], ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(\"Yahoo scrape skipped:\", e)\n",
    "\n",
    "if len(DF_SCRAPE):\n",
    "    DF_SCRAPE.to_csv(OUT_DIR / \"scraped_headlines.csv\", index=False, encoding=\"utf-8\")\n",
    "DF_SCRAPE.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104439c2",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Cleaning & Preprocessing\n",
    "We normalize text (lowercase, punctuation removal), remove stopwords, and lemmatize. For Transformer models, we will skip heavy normalization and rely on the tokenizer—so keep both clean and raw versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abe1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text.lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    t = re.sub(r\"[\\t\\n\\r]\", \" \", t)\n",
    "    t = re.sub(r\"[^a-z0-9\\s\\-\\$%.,!?']\", \" \", t)\n",
    "    return t.strip()\n",
    "\n",
    "def tokenize_lemmatize(text: str):\n",
    "    from nltk import word_tokenize\n",
    "    words = word_tokenize(text)\n",
    "    words = [LEMM.lemmatize(w) for w in words if w not in EN_STOP and w not in string.punctuation]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df = df_base.copy()\n",
    "df[\"text_clean\"] = df[\"text\"].apply(basic_clean).apply(tokenize_lemmatize)\n",
    "\n",
    "label_set = sorted(df[\"label\"].unique().tolist())\n",
    "label2id = {lab:i for i,lab in enumerate(label_set)}\n",
    "id2label = {i:lab for lab,i in label2id.items()}\n",
    "df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "\n",
    "print(\"Labels:\", label2id)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c6fbc",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Class balance\n",
    "counts = df[\"label\"].value_counts().sort_index()\n",
    "ax = counts.plot(kind=\"bar\", rot=0, title=\"Class distribution\")\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "# Lengths\n",
    "df[\"n_tokens\"] = df[\"text_clean\"].str.split().apply(len)\n",
    "df[\"n_chars\"] = df[\"text\"].str.len()\n",
    "\n",
    "plt.figure()\n",
    "df[\"n_tokens\"].hist(bins=30)\n",
    "plt.title(\"Token count distribution\")\n",
    "plt.xlabel(\"tokens\")\n",
    "plt.ylabel(\"freq\")\n",
    "plt.show()\n",
    "\n",
    "# Top words per class\n",
    "from collections import Counter\n",
    "def top_words(subset, k=20):\n",
    "    c = Counter()\n",
    "    for s in subset[\"text_clean\"]:\n",
    "        c.update(s.split())\n",
    "    return pd.DataFrame(c.most_common(k), columns=[\"word\",\"count\"])\n",
    "\n",
    "tops = {}\n",
    "for lab in label_set:\n",
    "    tops[lab] = top_words(df[df[\"label\"]==lab], k=20)\n",
    "\n",
    "for lab in label_set:\n",
    "    print(f\"Top words — {lab}\")\n",
    "    display(tops[lab])\n",
    "\n",
    "# WordClouds\n",
    "for lab in label_set:\n",
    "    try:\n",
    "        wc = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(df[df[\"label\"]==lab][\"text_clean\"]))\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"WordCloud — {lab}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"WordCloud error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb81dcb",
   "metadata": {},
   "source": [
    "## 5. Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2444489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label_id\"])\n",
    "train_df, val_df  = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df[\"label_id\"])\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e7056",
   "metadata": {},
   "source": [
    "## 6. Model 1 — Multinomial Naive Bayes (TF‑IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_nb = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9)),\n",
    "    (\"clf\", MultinomialNB(alpha=0.5))\n",
    "])\n",
    "\n",
    "tfidf_nb.fit(train_df[\"text_clean\"], train_df[\"label_id\"])\n",
    "pred_val = tfidf_nb.predict(val_df[\"text_clean\"])\n",
    "print(\"Validation — accuracy:\", accuracy_score(val_df[\"label_id\"], pred_val))\n",
    "print(classification_report(val_df[\"label_id\"], pred_val, target_names=label_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3f77e",
   "metadata": {},
   "source": [
    "## 7. Model 2 — BiLSTM (Keras/TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97987461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_BILSTM = True\n",
    "\n",
    "if USE_BILSTM:\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "        from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "        MAX_VOCAB = 20000\n",
    "        MAX_LEN = 40\n",
    "        tk = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<unk>\")\n",
    "        tk.fit_on_texts(train_df[\"text_clean\"].tolist())\n",
    "\n",
    "        def to_seqs(series):\n",
    "            return pad_sequences(tk.texts_to_sequences(series.tolist()), maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "        X_tr = to_seqs(train_df[\"text_clean\"])\n",
    "        X_va = to_seqs(val_df[\"text_clean\"])\n",
    "        y_tr = train_df[\"label_id\"].values\n",
    "        y_va = val_df[\"label_id\"].values\n",
    "\n",
    "        model = Sequential([\n",
    "            Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
    "            Bidirectional(LSTM(64, return_sequences=False)),\n",
    "            Dropout(0.3),\n",
    "            Dense(len(label_set), activation=\"softmax\")\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        hist = model.fit(X_tr, y_tr, validation_data=(X_va, y_va), epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "        bilstm_val_pred = np.argmax(model.predict(X_va), axis=1)\n",
    "        print(\"BiLSTM Validation — accuracy:\", accuracy_score(y_va, bilstm_val_pred))\n",
    "        print(classification_report(y_va, bilstm_val_pred, target_names=label_set))\n",
    "    except Exception as e:\n",
    "        print(\"BiLSTM section skipped due to error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dc12e",
   "metadata": {},
   "source": [
    "## 8. Model 3 — Transformer Fine‑Tuning (FinBERT or DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_TRANSFORMER = True\n",
    "TRANSFORMER_MODEL = \"ProsusAI/finbert\"  # or \"distilbert-base-uncased\"\n",
    "\n",
    "if USE_TRANSFORMER:\n",
    "    try:\n",
    "        from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "        import torch\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL)\n",
    "        num_labels = len(label_set)\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            TRANSFORMER_MODEL, num_labels=num_labels, \n",
    "            id2label={i:lab for i,lab in enumerate(label_set)},\n",
    "            label2id={lab:i for i,lab in enumerate(label_set)}\n",
    "        ).to(device)\n",
    "\n",
    "        class DS(torch.utils.data.Dataset):\n",
    "            def __init__(self, df):\n",
    "                self.df = df.reset_index(drop=True)\n",
    "            def __len__(self): return len(self.df)\n",
    "            def __getitem__(self, idx):\n",
    "                row = self.df.iloc[idx]\n",
    "                enc = tokenizer(row[\"text\"], truncation=True, padding=\"max_length\", max_length=64, return_tensors=\"pt\")\n",
    "                item = {k:v.squeeze(0) for k,v in enc.items()}\n",
    "                item[\"labels\"] = torch.tensor(int(row[\"label_id\"]), dtype=torch.long)\n",
    "                return item\n",
    "\n",
    "        train_ds = DS(train_df)\n",
    "        val_ds   = DS(val_df)\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=\"./transformer_out\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=2,\n",
    "            weight_decay=0.01,\n",
    "            logging_steps=50,\n",
    "            load_best_model_at_end=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            preds = np.argmax(logits, axis=1)\n",
    "            pr, rc, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            return {\"accuracy\": acc, \"precision\": pr, \"recall\": rc, \"f1\": f1}\n",
    "\n",
    "        trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=val_ds, compute_metrics=compute_metrics)\n",
    "        trainer.train()\n",
    "\n",
    "        eval_res = trainer.evaluate()\n",
    "        print(\"Transformer Validation metrics:\", eval_res)\n",
    "\n",
    "        TRANSFORMER_TRAINER = trainer\n",
    "    except Exception as e:\n",
    "        print(\"Transformer section skipped due to error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fe0d6",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "# NB\n",
    "try:\n",
    "    nb_test_pred = tfidf_nb.predict(test_df[\"text_clean\"])\n",
    "    nb_metrics = classification_report(test_df[\"label_id\"], nb_test_pred, target_names=label_set, output_dict=True)\n",
    "    results.append((\"TFIDF+NB\", nb_metrics[\"accuracy\"], nb_metrics[\"macro avg\"][\"f1-score\"]))\n",
    "except Exception as e:\n",
    "    print(\"NB test eval skipped:\", e)\n",
    "\n",
    "# BiLSTM\n",
    "try:\n",
    "    if USE_BILSTM and 'model' in globals():\n",
    "        from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        X_te = pad_sequences(tk.texts_to_sequences(test_df[\"text_clean\"].tolist()), maxlen=40, padding=\"post\", truncating=\"post\")\n",
    "        bilstm_test_pred = np.argmax(model.predict(X_te), axis=1)\n",
    "        bilstm_metrics = classification_report(test_df[\"label_id\"], bilstm_test_pred, target_names=label_set, output_dict=True)\n",
    "        results.append((\"BiLSTM\", bilstm_metrics[\"accuracy\"], bilstm_metrics[\"macro avg\"][\"f1-score\"]))\n",
    "except Exception as e:\n",
    "    print(\"BiLSTM test eval skipped:\", e)\n",
    "\n",
    "# Transformer\n",
    "try:\n",
    "    if USE_TRANSFORMER and 'TRANSFORMER_TRAINER' in globals():\n",
    "        import torch, numpy as np\n",
    "        class DS2(torch.utils.data.Dataset):\n",
    "            def __init__(self, df):\n",
    "                self.df = df.reset_index(drop=True)\n",
    "            def __len__(self): return len(self.df)\n",
    "            def __getitem__(self, idx):\n",
    "                row = self.df.iloc[idx]\n",
    "                enc = tokenizer(row[\"text\"], truncation=True, padding=\"max_length\", max_length=64, return_tensors=\"pt\")\n",
    "                item = {k:v.squeeze(0) for k,v in enc.items()}\n",
    "                item[\"labels\"] = torch.tensor(int(row[\"label_id\"]), dtype=torch.long)\n",
    "                return item\n",
    "        preds = TRANSFORMER_TRAINER.predict(DS2(test_df)).predictions\n",
    "        tr_test_pred = np.argmax(preds, axis=1)\n",
    "        tr_metrics = classification_report(test_df[\"label_id\"], tr_test_pred, target_names=label_set, output_dict=True)\n",
    "        results.append((\"Transformer\", tr_metrics[\"accuracy\"], tr_metrics[\"macro avg\"][\"f1-score\"]))\n",
    "except Exception as e:\n",
    "    print(\"Transformer test eval skipped:\", e)\n",
    "\n",
    "if results:\n",
    "    cmp_df = pd.DataFrame(results, columns=[\"model\",\"accuracy\",\"macro_f1\"]).sort_values(\"macro_f1\", ascending=False)\n",
    "    display(cmp_df)\n",
    "else:\n",
    "    print(\"No results to display. Make sure at least one model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea768aa0",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(y_true, y_pred, labels, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# NB CM (validation)\n",
    "try:\n",
    "    plot_cm(val_df[\"label_id\"], pred_val, label_set, \"NB (val) Confusion Matrix\")\n",
    "except Exception as e:\n",
    "    print(\"NB CM skipped:\", e)\n",
    "\n",
    "# BiLSTM CM (validation)\n",
    "try:\n",
    "    if 'bilstm_val_pred' in globals():\n",
    "        plot_cm(val_df[\"label_id\"], bilstm_val_pred, label_set, \"BiLSTM (val) Confusion Matrix\")\n",
    "except Exception as e:\n",
    "    print(\"BiLSTM CM skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d5bbe",
   "metadata": {},
   "source": [
    "## 10. Apply Best Model to New Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc51d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_with_nb(texts):\n",
    "    probs = tfidf_nb.predict_proba(texts)\n",
    "    preds = tfidf_nb.predict(texts)\n",
    "    return preds, probs\n",
    "\n",
    "def demo_application():\n",
    "    path = OUT_DIR / \"scraped_headlines.csv\"\n",
    "    if path.exists():\n",
    "        df_new = pd.read_csv(path)\n",
    "        texts = df_new[\"title\"].astype(str).tolist()\n",
    "    else:\n",
    "        texts = [\n",
    "            \"Tesla shares jump as deliveries beat expectations\",\n",
    "            \"Federal Reserve signals rates may stay higher for longer\",\n",
    "            \"Company Z misses revenue estimates; outlook trimmed\"\n",
    "        ]\n",
    "        df_new = pd.DataFrame({\"title\": texts})\n",
    "    preds, probs = predict_with_nb(texts)\n",
    "    df_new[\"pred_id\"] = preds\n",
    "    df_new[\"pred_label\"] = [id2label[i] for i in preds]\n",
    "    # map probabilities to labels\n",
    "    label_order = tfidf_nb.named_steps[\"clf\"].classes_\n",
    "    df_prob = pd.DataFrame(probs, columns=[id2label[i] for i in label_order])\n",
    "    df_out = pd.concat([df_new, df_prob], axis=1)\n",
    "    return df_out\n",
    "\n",
    "df_app = demo_application()\n",
    "df_app.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10bb13",
   "metadata": {},
   "source": [
    "## 11. Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c33901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df.to_csv(OUT_DIR / \"train.csv\", index=False)\n",
    "val_df.to_csv(OUT_DIR / \"val.csv\", index=False)\n",
    "test_df.to_csv(OUT_DIR / \"test.csv\", index=False)\n",
    "\n",
    "try:\n",
    "    import joblib\n",
    "    joblib.dump(tfidf_nb, OUT_DIR / \"tfidf_nb.joblib\")\n",
    "except Exception as e:\n",
    "    print(\"Model save skipped:\", e)\n",
    "\n",
    "print(\"Artifacts saved to ./outputs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21218ff4",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Notes on Customization & Justification\n",
    "\n",
    "- **Preprocessing**: Light normalization preserves finance symbols ($, %, -) that carry meaning.\n",
    "- **Imbalance**: Use class weights (deep models) or resampling. Track **macro F1**.\n",
    "- **Model choices**:\n",
    "  - **TF‑IDF + NB**: fast/strong for short texts.\n",
    "  - **BiLSTM**: captures limited order/negation.\n",
    "  - **FinBERT**: domain-specific; often best if compute allows.\n",
    "- **Optimization**:\n",
    "  - NB: tune `alpha`, `ngram_range`.\n",
    "  - BiLSTM: embedding dim, LSTM units, dropout, LR, epochs.\n",
    "  - Transformers: LR (1e‑5~5e‑5), batch (8–32), epochs (2–5), max length.\n",
    "- **Evaluation**:\n",
    "  - Prefer **macro F1** and per-class F1; add confusion matrices.\n",
    "  - Consider **time‑based split** when mixing old vs. recent news.\n",
    "- **Error analysis**:\n",
    "  - Inspect false positives/negatives; build keyword sanity lists (“beat”, “miss”, “downgrade”, “upgrade”).\n",
    "- **Reproducibility**:\n",
    "  - Fix seeds; save artifacts; export versions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
